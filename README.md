# VLLM ëª¨ë¸ ì„±ëŠ¥ ìë™ í‰ê°€ ì‹œìŠ¤í…œ

> ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ì— ë°°í¬ëœ **VLLM** ì„œë¹™ ëª¨ë¸ì„ **Deepeval** ë° **Evalchemy** ([mlfoundations/Evalchemy](https://github.com/mlfoundations/Evalchemy))ë¡œ ì§€ì†ì Â·ìë™ìœ¼ë¡œ í‰ê°€í•˜ì—¬ ëª¨ë¸ í’ˆì§ˆ ì§€í‘œë¥¼ í™•ë³´í•˜ê³  í’ˆì§ˆ í‡´í™”ë¥¼ ì¦‰ì‹œ íƒì§€í•˜ëŠ” CI/CD íŒŒì´í”„ë¼ì¸

[![CI](https://github.com/your-org/vllm-eval/actions/workflows/lint-test.yml/badge.svg)](https://github.com/your-org/vllm-eval/actions/workflows/lint-test.yml)
[![Image Build](https://github.com/your-org/vllm-eval/actions/workflows/image-build.yml/badge.svg)](https://github.com/your-org/vllm-eval/actions/workflows/image-build.yml)

## ğŸ¯ ëª©ì 

- **ëª¨ë¸ ë¦´ë¦¬ìŠ¤ë§ˆë‹¤** ê°ê´€ì  í’ˆì§ˆ ì§€í‘œ í™•ë³´
- **í’ˆì§ˆ í‡´í™”(regression)** ì¦‰ì‹œ íƒì§€
- **Microsoft Teams ì±„ë„**ì— ì‹¤ì‹œê°„ ë¦¬í¬íŒ…/ì•Œë¦¼ ì œê³µ
- **í‘œì¤€ ë²¤ì¹˜ë§ˆí¬**(ARC, HellaSwag, MMLU ë“±) ë° **ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­** ìë™ í‰ê°€

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TD
    A[GHCR Push Event] --> B[Argo Events Sensor]
    B --> C[Argo Workflow Trigger]
    
    subgraph "Workflow Steps"
        C --> D[prepare-dataset]
        D --> E[deepeval-runner]
        E --> F[evalchemy-runner]
        F --> G[aggregate-metrics]
    end
    
    G --> H[ClickHouse]
    G --> I[Grafana Dashboard]
    G --> J[Teams Notification]
    
    subgraph "Storage"
        K[MinIO - Datasets]
        L[PVC - Raw Logs]
    end
    
    D --> K
    E --> L
    F --> L
```

## ğŸ“ ì£¼ìš” í´ë”Â·íŒŒì¼ ì„¤ëª…

### `.github/workflows/`
- **`ci.yml`** â€“ ruff (ì •ì  ë¶„ì„) + pytest + ìŠ¤í‚¤ë§ˆ ê²€ì¦ ìˆ˜í–‰
- **`evalchemy-build.yml`, `standard-evalchemy-build.yml`, `vllm-benchmark-build.yml`** â€“ ê° í‰ê°€ í™˜ê²½ì— ë§ëŠ” Docker ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•˜ì—¬ GHCRì— í‘¸ì‹œí•©ë‹ˆë‹¤.
- **`evalchemy-deploy.yml`, `standard-evalchemy-deploy.yml`, `vllm-benchmark-deploy.yml`** â€“ ë¹Œë“œëœ ì´ë¯¸ì§€ë¥¼ ì¿ ë²„ë„¤í‹°ìŠ¤ í™˜ê²½ì— ë°°í¬í•˜ëŠ” ì›Œí¬í”Œë¡œìš°ì…ë‹ˆë‹¤.

### `charts/`
Helm ì°¨íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¿ ë²„ë„¤í‹°ìŠ¤ ì• í”Œë¦¬ì¼€ì´ì…˜(ClickHouse, Grafana, Argo Workflows ë“±)ì„ íŒ¨í‚¤ì§•í•˜ê³  ë°°í¬ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.

### `k8s/`
- **`evalchemy-job.yaml`, `standard-evalchemy-job.yaml`, `vllm-benchmark-job.yaml`** â€“ Argo Workflowsì—ì„œ ì‚¬ìš©í•  ê° í‰ê°€ ë‹¨ê³„ë¥¼ ì •ì˜í•˜ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ Job/Workflow í…œí”Œë¦¿ì…ë‹ˆë‹¤.

### `eval/`
- **`deepeval_tests/`** â€“ PyTest ìŠ¤íƒ€ì¼ ìŠ¤ìœ„íŠ¸, DeepEval ì»¤ìŠ¤í…€ Metric ìœ„ì¹˜
- **`evalchemy/`** â€“ LM-evaluation-harness ë˜í¼; ARC, MMLU, Ko-MMLU ë“± êµ¬ì„±

### `datasets/`
- SHA-256 ë§¤ë‹ˆí˜ìŠ¤íŠ¸ YAMLë§Œ ë³´ê´€â€”ì›ë³¸ ë°ì´í„°ëŠ” MinIO
- `dedup_datasets.py`ê°€ MinHash-LSHë¡œ ì¤‘ë³µ ì œê±°ë¥¼ ìˆ˜í–‰

### `scripts/`
- **`aggregate_metrics.py`** â€“ ClickHouseì— ê²°ê³¼ ê¸°ë¡
- ë¡œì»¬ ì‹¤í–‰Â·ë””ë²„ê·¸ìš© ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸ í¬í•¨

### `docker/`
- **`deepeval.Dockerfile`** â€“ Deepeval ê¸°ë°˜ PyTest í‰ê°€ ëŸ¬ë„ˆ
- **`evalchemy.Dockerfile`** â€“ Evalchemy ê¸°ë°˜ í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ ëŸ¬ë„ˆ
- **`standard-evalchemy.Dockerfile`** â€“ í‘œì¤€í™”ëœ Evalchemy í•˜ë„¤ìŠ¤ ì´ë¯¸ì§€
- **`nvidia-eval.Dockerfile`** â€“ AIME/LiveCodeBench ë“± NVIDIA í‰ê°€ ëŸ¬ë„ˆ
- **`vllm-benchmark.Dockerfile`** â€“ VLLM ê³µì‹ benchmark_serving.py ê¸°ë°˜ ì„±ëŠ¥ ì¸¡ì • ì»¨í…Œì´ë„ˆ

### `Makefile`
- `make kind-deploy`, `make helm-install`, `make run-tests` ë“± ê³µí†µ íƒ€ê¹ƒ

## ğŸ³ Docker ì´ë¯¸ì§€: ë¹Œë“œ & ì‹¤í–‰ ì˜ˆì‹œ

ì•„ë˜ ì˜ˆì‹œëŠ” ê° ì´ë¯¸ì§€ì˜ ëŒ€í‘œì ì¸ ë¹Œë“œ/ì‹¤í–‰ ë°©ë²•ì…ë‹ˆë‹¤. í”Œë«í¼ë³„ ìƒì„¸ ëª…ë ¹ì€ `docker/README.md`ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

### Evalchemy

```bash
# Build (linux/amd64)
docker buildx build --platform linux/amd64 \
  -f docker/evalchemy.Dockerfile \
  -t ghcr.io/thakicloud/evalchemy-linux:latest .

# Run
docker run --rm \
  -v $(pwd)/results:/app/results \
  -v $(pwd)/parsed:/app/parsed \
  -e MODEL_ENDPOINT="http://host.docker.internal:8000/v1/completions" \
  -e MODEL_NAME="qwen3-8b" \
  -e LOG_LEVEL="DEBUG" \
  ghcr.io/thakicloud/evalchemy-linux:latest
```

### Standard Evalchemy

```bash
# Build (linux/amd64)
docker buildx build --platform linux/amd64 \
  -f docker/standard-evalchemy.Dockerfile \
  -t ghcr.io/thakicloud/standard-evalchemy-linux:latest .

# Run
docker run --rm \
  -v $(pwd)/results:/app/results \
  -v $(pwd)/parsed:/app/parsed \
  -e MODEL_ENDPOINT="http://host.docker.internal:8000/v1/completions" \
  -e MODEL_NAME="qwen3-8b" \
  ghcr.io/thakicloud/standard-evalchemy-linux:latest
```

### NVIDIA Eval (AIME / LiveCodeBench)

```bash
# Build (linux/amd64)
docker buildx build --platform linux/amd64 \
  -f docker/nvidia-eval.Dockerfile \
  -t ghcr.io/thakicloud/nvidia-eval-linux:latest .

# Run (AIME)
docker run --rm \
  -v $(pwd)/results:/app/results \
  -v $(pwd)/parsed:/app/parsed \
  -e MODEL_ENDPOINT="http://host.docker.internal:8000/v1" \
  -e MODEL_NAME="qwen3-8b" \
  -e EVAL_TYPE="aime" \
  -e MAX_TOKENS="32768" \
  ghcr.io/thakicloud/nvidia-eval-linux:latest

# Run (AIME + LiveCodeBench)
docker run --rm \
  -v $(pwd)/results:/app/results \
  -v $(pwd)/parsed:/app/parsed \
  -e MODEL_ENDPOINT="http://host.docker.internal:8000/v1" \
  -e MODEL_NAME="qwen3-8b" \
  -e EVAL_TYPE="both" \
  ghcr.io/thakicloud/nvidia-eval-linux:latest
```

### VLLM Benchmark

```bash
# Build (linux/amd64)
docker buildx build --platform linux/amd64 \
  -f docker/vllm-benchmark.Dockerfile \
  -t ghcr.io/thakicloud/vllm-benchmark-linux:latest .

# Run
docker run --rm \
  --network host \
  -v $(pwd)/results:/app/results \
  -v $(pwd)/parsed:/app/parsed \
  -e MODEL_ENDPOINT="http://localhost:8080" \
  -e MODEL_NAME="Qwen/Qwen2-0.5B" \
  -e TOKENIZER="gpt2" \
  ghcr.io/thakicloud/vllm-benchmark-linux:latest
```

## â˜¸ï¸ Kubernetesì—ì„œ ì‹¤í–‰ (k8s/)

ë‹¤ìŒ Job ë§¤ë‹ˆí˜ìŠ¤íŠ¸ëŠ” `k8s/` í´ë”ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ í’€ì„ ìœ„í•´ GHCR ì‹œí¬ë¦¿ì´ í•„ìš”í•©ë‹ˆë‹¤.

### ì‚¬ì „ ì¤€ë¹„: GHCR ì´ë¯¸ì§€ Pull Secret

```bash
kubectl create secret docker-registry ghcr-secret \
  --docker-server=ghcr.io \
  --docker-username="<your_github_username>" \
  --docker-password="<your_github_pat>"
```

### ê³µí†µ ì‹¤í–‰/ëª¨ë‹ˆí„°ë§

```bash
# ì ìš©
kubectl apply -f k8s/evalchemy-job.yaml
kubectl apply -f k8s/standard-evalchemy-job.yaml
kubectl apply -f k8s/vllm-benchmark-job.yaml
kubectl apply -f k8s/nvidia-eval-job.yaml

# ìƒíƒœ í™•ì¸
kubectl get jobs

# ë¡œê·¸ í™•ì¸
kubectl logs -f job/evalchemy
kubectl logs -f job/standard-evalchemy
kubectl logs -f job/vllm-benchmark
kubectl logs -f job/nvidia-eval
```

### í™˜ê²½ ë³€ìˆ˜ (ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ê¸°ì¤€)

- Evalchemy (`k8s/evalchemy-job.yaml`)
  - `MODEL_ENDPOINT="http://vllm.vllm:8000/v1/completions"`
  - `BACKEND_API="http://10.7.60.71:10301"`
  - `MAX_TOKENS="1400"`
  - `EVAL_CONFIG_PATH="/app/configs/eval_config.json"`

- Standard Evalchemy (`k8s/standard-evalchemy-job.yaml`)
  - `MODEL_ENDPOINT="http://vllm.vllm:8000/v1/completions"`
  - `BACKEND_API="http://10.7.60.71:10301"`
  - `MAX_TOKENS="140"`
  - `HF_TOKEN=""` (í•„ìš” ì‹œ ì„¤ì •)
  - `EVAL_CONFIG_PATH="/app/configs/eval_config.json"`

- VLLM Benchmark (`k8s/vllm-benchmark-job.yaml`)
  - `MODEL_ENDPOINT="http://vllm.vllm:8000"` (Base URL)
  - `RANDOM_INPUT_LEN="512"`
  - `MAX_CONCURRENCY="1"`
  - `BACKEND_API="http://10.7.60.71:10301"`
  - `CONFIG_PATH="/app/configs/eval_config.json"`

- NVIDIA Eval (`k8s/nvidia-eval-job.yaml`)
  - `MODEL_ENDPOINT="http://vllm.vllm:8000/v1"`
  - `BACKEND_API="http://10.7.60.71:10301"`
  - `MAX_TOKENS="1400"`
  - `EVAL_TYPE="aime"` (ê°€ëŠ¥: `aime` | `lcb` | `both`)
  - `OUTPUT_DIR="output"`

### ì°¸ê³  ì‚¬í•­

- Jobë“¤ì€ ê¸°ë³¸ì ìœ¼ë¡œ ê²°ê³¼ ë””ë ‰í„°ë¦¬(`/app/results`, `/app/parsed`)ë¥¼ ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì— ìƒì„±í•©ë‹ˆë‹¤. ì¥ê¸° ë³´ì¡´ì´ í•„ìš”í•˜ë©´ PVC ë§ˆìš´íŠ¸ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
- `nodeAffinity`ê°€ CPU ë…¸ë“œ ì„ í˜¸/ê³ ì •ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. GPUê°€ í•„ìš”í•œ ì›Œí¬ë¡œë“œì˜ ê²½ìš° GPU ë…¸ë“œë¡œ ìŠ¤ì¼€ì¤„ë§ ì •ì±…ì„ ì¡°ì •í•˜ì„¸ìš”.
- `MODEL_ENDPOINT`ëŠ” ê° í”„ë ˆì„ì›Œí¬ ê¸°ëŒ€ í˜•ì‹ì´ ë‹¤ë¦…ë‹ˆë‹¤. VLLM BenchmarkëŠ” Base URL, Evalchemy/Standard EvalchemyëŠ” `/v1/completions`, NVIDIA Evalì€ `/v1` Baseë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. Kind í´ëŸ¬ìŠ¤í„° + Argo + ClickHouse ë¶€íŠ¸ìŠ¤íŠ¸ë©
```bash
make kind-deploy
```

### 2. í…ŒìŠ¤íŠ¸ ëª¨ë¸ ì´ë¯¸ì§€ ë¹Œë“œ & Push
```bash
export IMG_TAG=release-0.0.1
docker build -t ghcr.io/<org>/vllm:${IMG_TAG} .
docker push ghcr.io/<org>/vllm:${IMG_TAG}
```

### 3. ì›Œí¬í”Œë¡œ ëª¨ë‹ˆí„°ë§
```bash
argo watch -n mlops -w
```


## âš¡ VLLM ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

VLLM ì„œë¹™ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ëŠ” ë…ë¦½ì ì¸ ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### ğŸ¯ ì„±ëŠ¥ ë©”íŠ¸ë¦­
- **TTFT (Time to First Token)**: ì²« í† í° ìƒì„± ì‹œê°„
- **TPOT (Time per Output Token)**: í† í°ë‹¹ ìƒì„± ì‹œê°„  
- **ITL (Inter-token Latency)**: í† í° ê°„ ì§€ì—°ì‹œê°„
- **E2EL (End-to-End Latency)**: ì „ì²´ ì‘ë‹µ ì‹œê°„
- **Throughput**: ì´ˆë‹¹ í† í° ì²˜ë¦¬ëŸ‰
- **Success Rate**: ìš”ì²­ ì„±ê³µë¥ 

### ğŸƒâ€â™‚ï¸ ë¹ ë¥¸ ì‹¤í–‰

```bash
# 1. Docker ì´ë¯¸ì§€ ë¹Œë“œ (ì˜ˆ: linux/amd64)
docker buildx build --platform linux/amd64 \
  -f docker/vllm-benchmark.Dockerfile \
  -t vllm-benchmark:latest .

# 2. ë‹¨ì¼ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ (í‘œì¤€í™”ëœ ê²½ë¡œ/ë³€ìˆ˜ ì‚¬ìš©)
docker run --rm \
  --network host \
  -v $(pwd)/results:/app/results \
  -v $(pwd)/parsed:/app/parsed \
  -e MODEL_ENDPOINT=http://your-vllm-server:8000 \
  -e MODEL_NAME=Qwen/Qwen3-8B \
  -e MAX_CONCURRENCY=4 \
  vllm-benchmark:latest

# 2-1. ìƒ˜í”Œ
docker run --rm \
  --network host \
  -v $(pwd)/results:/app/results \
  -v $(pwd)/parsed:/app/parsed \
  -e MODEL_ENDPOINT=http://your-vllm-server:8000 \
  -e MODEL_NAME=Qwen/Qwen3-8B \
  -e SERVED_MODEL_NAME=qwen3-8b \
  -e MAX_CONCURRENCY=1 \
  -e RANDOM_INPUT_LEN=1024 \
  -e RANDOM_OUTPUT_LEN=1024 \
  vllm-benchmark:latest

# 3. ë‹¤ì¤‘ ì‹œë‚˜ë¦¬ì˜¤ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
chmod +x scripts/run_vllm_performance_benchmark.sh
MODEL_ENDPOINT=http://your-vllm-server:8000 ./scripts/run_vllm_performance_benchmark.sh

# 4. ê²°ê³¼ ë¶„ì„
python3 scripts/analyze_performance_results.py results/performance
```

### ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ì‹œë‚˜ë¦¬ì˜¤

`configs/vllm_benchmark.json`ì—ì„œ ì„¤ì •:

| ì‹œë‚˜ë¦¬ì˜¤ | ì„¤ëª… | ë™ì‹œì„± | ì…ë ¥/ì¶œë ¥ í† í° |
|----------|------|--------|----------------|
| `basic_performance` | ê¸°ë³¸ ì„±ëŠ¥ ì¸¡ì • | 1 | 1024/128 |
| `concurrency_test` | ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ | 10 | 512/256 |
| `long_context` | ê¸´ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ | 2 | 4096/512 |
| `stress_test` | ê³ ë¶€í•˜ ìŠ¤íŠ¸ë ˆìŠ¤ | 20 | 2048/1024 |

### ğŸ›ï¸ í™˜ê²½ë³€ìˆ˜ ì„¤ì •

```bash
# ê¸°ë³¸ ì„¤ì • (í‘œì¤€í™”ëœ ë³€ìˆ˜)
MODEL_ENDPOINT=http://localhost:8000   # VLLM ì„œë²„ Base URL
MODEL_NAME=Qwen/Qwen3-8B              # ëª¨ë¸ ì´ë¦„
SERVED_MODEL_NAME=qwen3-8b            # ì„œë¹™ ëª¨ë¸ëª…
MAX_CONCURRENCY=1                     # ìµœëŒ€ ë™ì‹œ ìš”ì²­
RANDOM_INPUT_LEN=1024                 # ì…ë ¥ í† í° ê¸¸ì´
RANDOM_OUTPUT_LEN=128                 # ì¶œë ¥ í† í° ê¸¸ì´
TZ=Asia/Seoul                         # ì‹œê°„ëŒ€ ì„¤ì •
```
### ğŸ“ˆ ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼

```
ğŸ“Š VLLM ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë¶„ì„ ê²°ê³¼
============================================================

ğŸ¯ ì‹œë‚˜ë¦¬ì˜¤: basic_performance
----------------------------------------
âœ… ì„±ê³µë¥ : 100.0% (100/100)
â±ï¸  ì´ ì†Œìš”ì‹œê°„: 45.2ì´ˆ
ğŸ”„ ìš”ì²­ ì²˜ë¦¬ëŸ‰: 2.21 req/s
ğŸ“¤ í† í° ì²˜ë¦¬ëŸ‰: 283.4 tok/s
ğŸš€ TTFT í‰ê· : 82.1ms
ğŸš€ TTFT P95: 156.3ms
âš¡ TPOT í‰ê· : 28.5ms
âš¡ TPOT P95: 45.2ms

ğŸ† ì¢…í•© ì„±ëŠ¥ ë“±ê¸‰: A
âœ¨ ëª¨ë“  ì„±ëŠ¥ ì§€í‘œê°€ ìš°ìˆ˜í•©ë‹ˆë‹¤!

```
## ğŸ”„ ë¸Œëœì¹­ & ë¦´ë¦¬ìŠ¤ íƒœê·¸

| ë¸Œëœì¹˜ | íŠ¹ì§• |
|--------|------|
| `main` | ë³´í˜¸ ë¸Œëœì¹˜Â·ìŠ¤í…Œì´ì§• í´ëŸ¬ìŠ¤í„° ìë™ ë°°í¬ |
| `release/*` | PR ë³‘í•© ì‹œ `release-{semver}` ì´ë¯¸ì§€ ë¹Œë“œÂ·GHCR í‘¸ì‹œâ†’Argo Trigger |

`docs/` ë¸Œëœì¹˜ë¥¼ ë”°ë¡œ ë‘ì–´ MkDocs ê¸°ë°˜ GitHub Pages ìš´ì˜ ê°€ëŠ¥.

## ğŸ” ì§€ì†ì  í”¼ë“œë°± ë£¨í”„

1. **ê°œë°œì**ê°€ `release-0.3.1` ì´ë¯¸ì§€ë¥¼ Push â†’ **GHCR Webhook** ë°œìƒ
2. **Argo Events Sensor**ê°€ ê°ì§€ â†’ **Argo Workflow** ì‹¤í–‰
3. **Workflow**ê°€ Deepeval(CPU) â†’ Evalchemy(GPU) ìˆœìœ¼ë¡œ ìˆ˜í–‰
4. `aggregate_metrics.py`ê°€ **ClickHouse**ì— ê²°ê³¼ ì €ì¥, **Grafana**ê°€ ìë™ ê°±ì‹ 
5. **Adaptive Card**ê°€ ìš”ì•½(ì„±ê³µ/ì‹¤íŒ¨, ì§€í‘œ ë³€í™”)ì„ **Teams ì±„ë„**ì— ì „ì†¡

## ğŸ“Š ë°ì´í„°ì…‹Â·ë²¤ì¹˜ë§ˆí¬

| ì¹´í…Œê³ ë¦¬ | ì˜ˆì‹œ | ê´€ë¦¬ ë°©ì‹ |
|----------|------|-----------|
| í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ | ARC, HellaSwag, MMLU | Evalchemy Preset |
| í•œêµ­ì–´ ë²¤ì¹˜ë§ˆí¬ | Ko-MMLU, Ko-ARC | ë³„ë„ bucket `ko-benchmark` |
| ë¦¬ê·¸ë ˆì…˜ ì„¸íŠ¸ | ì„œë¹„ìŠ¤ ì¿¼ë¦¬ ìŠ¤ëƒ…ìƒ· 1k | ì¼ 1íšŒ ìµëª…í™” & SHA-256 Dedup |

**Deduplication** ì „ëµ: SHA-1/256 Hash â†’ Exact Match ì œê±° â†’ Near-Dup (LSH + Levenshtein < 0.2) í•„í„°ë¡œ DeepevalÂ·Evalchemy ì–‘ì¸¡ ë°ì´í„°ì…‹ ì¤‘ë³µ ì œê±°.

## ğŸ¯ ì„±ê³µ ì§€í‘œ

| í•­ëª© | ëª©í‘œê°’ | ì¸¡ì • ë°©ë²• |
|------|--------|-----------|
| ë¦´ë¦¬ìŠ¤â€‘toâ€‘ë¦¬í¬íŠ¸ ì§€ì—° | â‰¤ 2h | íŒŒì´í”„ë¼ì¸ ì™„ë£Œ íƒ€ì„ìŠ¤íƒ¬í”„ |
| í’ˆì§ˆ í‡´í™” ê°ì§€ìœ¨ | â‰¥ 95% | Knownâ€‘Bad ë¦¬ê·¸ë ˆì…˜ ì„¸íŠ¸ |
| íŒŒì´í”„ë¼ì¸ ì•ˆì •ì„± | ì‹¤íŒ¨ < 1%/ì›” | CronJob ì„±ê³µë¥  |

## ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ

- **ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜**: Kubernetes
- **ì›Œí¬í”Œë¡œ**: Argo Workflows, Argo Events
- **í‰ê°€ í”„ë ˆì„ì›Œí¬**: Deepeval, Evalchemy ([mlfoundations/Evalchemy](https://github.com/mlfoundations/Evalchemy))
- **ì €ì¥ì†Œ**: ClickHouse (ë©”íŠ¸ë¦­), MinIO (ë°ì´í„°ì…‹)
- **ëª¨ë‹ˆí„°ë§**: Grafana, Prometheus
- **ì•Œë¦¼**: Microsoft Teams Webhooks
- **íŒ¨í‚¤ì§•**: Helm Charts

## ğŸ“ˆ í–¥í›„ í™•ì¥ ì•„ì´ë””ì–´

| ì˜ì—­ | ì•„ì´ë””ì–´ |
|------|----------|
| **ë³´ì•ˆ** | OPA Gatekeeperë¡œ ServiceAccount ì œì•½ |
| **ë¹„ìš©** | Spot-node taint + Argo node-selector |
| **ë°ì´í„°** | ì¤‘ë³µ í•´ì‹œë¥¼ Milvusë¡œ ì´ë™í•´ ë¹ ë¥¸ ì¡°íšŒ |

## ğŸ” ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

- **ServiceAccount** ìµœì†Œ RBAC ê¶Œí•œ
- **Secrets** External Secret Operator ì—°ë™
- ëª¨ë“  **RUN_ID** ë³„ JSONL ë¡œê·¸ S3 â‰¥ 90ì¼ ë³´ì¡´

## ğŸ“š ë¬¸ì„œ

- [ì•„í‚¤í…ì²˜ ë¬¸ì„œ](docs/architecture.md)
- [ë²¤ì¹˜ë§ˆí¬ ì¶”ê°€ ê°€ì´ë“œ](docs/how-to-add-benchmark.md)
- [ê¸°ì—¬ ê°€ì´ë“œ](docs/CONTRIBUTING.md)

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ“ ì—°ë½ì²˜

- **ì œí’ˆ ì˜¤ë„ˆ**: [Product Owner Email]
- **ML Ops**: [MLOps Team Email]  
- **í”Œë«í¼ Ops**: [Platform Team Email]

---

> ğŸš€ **VLLM ëª¨ë¸ì˜ í’ˆì§ˆì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  ê°œì„ í•˜ì„¸ìš”!**