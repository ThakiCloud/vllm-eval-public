# VLLM ëª¨ë¸ ì„±ëŠ¥ ìë™ í‰ê°€ ì‹œìŠ¤í…œ

> ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ì— ë°°í¬ëœ **VLLM** ì„œë¹™ ëª¨ë¸ì„ **Deepeval** ë° **Evalchemy** ([mlfoundations/Evalchemy](https://github.com/mlfoundations/Evalchemy))ë¡œ ì§€ì†ì Â·ìë™ìœ¼ë¡œ í‰ê°€í•˜ì—¬ ëª¨ë¸ í’ˆì§ˆ ì§€í‘œë¥¼ í™•ë³´í•˜ê³  í’ˆì§ˆ í‡´í™”ë¥¼ ì¦‰ì‹œ íƒì§€í•˜ëŠ” CI/CD íŒŒì´í”„ë¼ì¸

[![CI](https://github.com/your-org/vllm-eval/actions/workflows/lint-test.yml/badge.svg)](https://github.com/your-org/vllm-eval/actions/workflows/lint-test.yml)
[![Image Build](https://github.com/your-org/vllm-eval/actions/workflows/image-build.yml/badge.svg)](https://github.com/your-org/vllm-eval/actions/workflows/image-build.yml)

## ğŸ¯ ëª©ì 

- **ëª¨ë¸ ë¦´ë¦¬ìŠ¤ë§ˆë‹¤** ê°ê´€ì  í’ˆì§ˆ ì§€í‘œ í™•ë³´
- **í’ˆì§ˆ í‡´í™”(regression)** ì¦‰ì‹œ íƒì§€
- **Microsoft Teams ì±„ë„**ì— ì‹¤ì‹œê°„ ë¦¬í¬íŒ…/ì•Œë¦¼ ì œê³µ
- **í‘œì¤€ ë²¤ì¹˜ë§ˆí¬**(ARC, HellaSwag, MMLU ë“±) ë° **ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­** ìë™ í‰ê°€

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TD
    A[GHCR Push Event] --> B[Argo Events Sensor]
    B --> C[Argo Workflow Trigger]
    
    subgraph "Workflow Steps"
        C --> D[prepare-dataset]
        D --> E[deepeval-runner]
        E --> F[evalchemy-runner]
        F --> G[aggregate-metrics]
    end
    
    G --> H[ClickHouse]
    G --> I[Grafana Dashboard]
    G --> J[Teams Notification]
    
    subgraph "Storage"
        K[MinIO - Datasets]
        L[PVC - Raw Logs]
    end
    
    D --> K
    E --> L
    F --> L
```

## ğŸ“ ì£¼ìš” í´ë”Â·íŒŒì¼ ì„¤ëª…

### `.github/workflows/`
- **`image-build.yml`** â€“ deepeval, evalchemy, workflow-tools ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•´ GHCRì— `release-*` íƒœê·¸ë¡œ í‘¸ì‹œ. Push ì´ë²¤íŠ¸ê°€ Argo Events ì„¼ì„œë¥¼ íŠ¸ë¦¬ê±°
- **`lint-test.yml`** â€“ ruff (ì •ì  ë¶„ì„) + pytest + ìŠ¤í‚¤ë§ˆ ê²€ì¦ ìˆ˜í–‰

### `charts/`
Helm ì°¨íŠ¸ë¡œ ì¸í”„ë¼ ë²„ì „ì„ ê³ ì •í•˜ê³  ê°„í¸ ì—…ê·¸ë ˆì´ë“œ:
- **`clickhouse/`** â€“ Altinity ì»¤ë®¤ë‹ˆí‹° ì°¨íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ìŠ¤íƒ€í„°
- **`argo-workflows/`** â€“ HA = 2 replicas ì„¤ì • ì„œë¸Œì°¨íŠ¸
- **`grafana/`** â€“ "LLM Quality Overview" JSON ëŒ€ì‹œë³´ë“œë¥¼ ì‚¬ì „ ë¡œë“œ

### `infra/`
- **`argo-events/`** â€“ GHCR Webhookì„ ìˆ˜ì‹ í•˜ëŠ” Sensor & Trigger
- **`argo-workflows/`** â€“ 4-ìŠ¤í… DAG(prepare-datasetâ†’deepevalâ†’evalchemyâ†’aggregate)
- **`teams-webhook/`** â€“ Teams Webhook URLì„ ë‹´ì€ Secretê³¼ Adaptive Card ì „ì†¡ìš© Job í…œí”Œë¦¿

### `eval/`
- **`deepeval_tests/`** â€“ PyTest ìŠ¤íƒ€ì¼ ìŠ¤ìœ„íŠ¸, DeepEval ì»¤ìŠ¤í…€ Metric ìœ„ì¹˜
- **`evalchemy/`** â€“ LM-evaluation-harness ë˜í¼; ARC, MMLU, Ko-MMLU ë“± êµ¬ì„±

### `datasets/`
- SHA-256 ë§¤ë‹ˆí˜ìŠ¤íŠ¸ YAMLë§Œ ë³´ê´€â€”ì›ë³¸ ë°ì´í„°ëŠ” MinIO
- `dedup_datasets.py`ê°€ MinHash-LSHë¡œ ì¤‘ë³µ ì œê±°ë¥¼ ìˆ˜í–‰

### `scripts/`
- **`aggregate_metrics.py`** â€“ ClickHouseì— ê²°ê³¼ ê¸°ë¡
- ë¡œì»¬ ì‹¤í–‰Â·ë””ë²„ê·¸ìš© ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸ í¬í•¨

### `docker/`
- **`deepeval.Dockerfile`** â€“ deepevalê³¼ í…ŒìŠ¤íŠ¸ ì½”ë“œ í¬í•¨
- **`evalchemy.Dockerfile`** â€“ mlfoundations/Evalchemy ê¸°ë°˜ í‰ê°€ ì»¨í…Œì´ë„ˆ
- **`legacy-evalchemy.Dockerfile`** â€“ ê¸°ì¡´ lm-eval ê¸°ë°˜ ì»¨í…Œì´ë„ˆ (í˜¸í™˜ì„± ìœ ì§€)
- **`workflow-tools.Dockerfile`** â€“ yq, awscli, mc ë“± ì›Œí¬í”Œë¡œ ë³´ì¡° íˆ´
- **`vllm-benchmark.Dockerfile`** â€“ VLLM ê³µì‹ benchmark_serving.py ê¸°ë°˜ ì„±ëŠ¥ ì¸¡ì • ì»¨í…Œì´ë„ˆ

### `Makefile`
- `make kind-deploy`, `make helm-install`, `make run-tests` ë“± ê³µí†µ íƒ€ê¹ƒ

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. Kind í´ëŸ¬ìŠ¤í„° + Argo + ClickHouse ë¶€íŠ¸ìŠ¤íŠ¸ë©
```bash
make kind-deploy
```

### 2. í…ŒìŠ¤íŠ¸ ëª¨ë¸ ì´ë¯¸ì§€ ë¹Œë“œ & Push
```bash
export IMG_TAG=release-0.0.1
docker build -t ghcr.io/<org>/vllm:${IMG_TAG} .
docker push ghcr.io/<org>/vllm:${IMG_TAG}
```

### 3. ì›Œí¬í”Œë¡œ ëª¨ë‹ˆí„°ë§
```bash
argo watch -n mlops -w
```


## âš¡ VLLM ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

VLLM ì„œë¹™ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ëŠ” ë…ë¦½ì ì¸ ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### ğŸ¯ ì„±ëŠ¥ ë©”íŠ¸ë¦­
- **TTFT (Time to First Token)**: ì²« í† í° ìƒì„± ì‹œê°„
- **TPOT (Time per Output Token)**: í† í°ë‹¹ ìƒì„± ì‹œê°„  
- **ITL (Inter-token Latency)**: í† í° ê°„ ì§€ì—°ì‹œê°„
- **E2EL (End-to-End Latency)**: ì „ì²´ ì‘ë‹µ ì‹œê°„
- **Throughput**: ì´ˆë‹¹ í† í° ì²˜ë¦¬ëŸ‰
- **Success Rate**: ìš”ì²­ ì„±ê³µë¥ 

### ğŸƒâ€â™‚ï¸ ë¹ ë¥¸ ì‹¤í–‰

```bash
# 1. Docker ì´ë¯¸ì§€ ë¹Œë“œ
docker build -f docker/vllm-benchmark.Dockerfile -t vllm-benchmark:latest .

# 2. ë‹¨ì¼ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
docker run --rm \
  -v $(pwd)/results:/results \
  -e VLLM_ENDPOINT=http://your-vllm-server:8000 \
  -e MODEL_NAME=Qwen/Qwen3-8B \
  -e MAX_CONCURRENCY=4 \
  -e TZ=Asia/Seoul \
  vllm-benchmark:latest

# 2-1. ìƒ˜í”Œ
docker run -v $(pwd)/results:/results -v $(pwd)/parsed:/parsed \
  -e VLLM_ENDPOINT=http://your-vllm-server:8000 \
  -e MODEL_NAME=Qwen/Qwen3-8B \
  -e SERVED_MODEL_NAME=qwen3-8b \
  -e MAX_CONCURRENCY=1 \
  -e RANDOM_INPUT_LEN=1024 \
  -e RANDOM_OUTPUT_LEN=1024 \
  vllm-benchmark:latest

# 3. ë‹¤ì¤‘ ì‹œë‚˜ë¦¬ì˜¤ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
chmod +x scripts/run_vllm_performance_benchmark.sh
./scripts/run_vllm_performance_benchmark.sh

# 3-1. ë‹¤ì¤‘ ì‹œë‚˜ë¦¬ì˜¤ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ + endpoint ì§€ì •
VLLM_ENDPOINT=http://your-vllm-server:8000 ./scripts/run_vllm_performance_benchmark.sh

# 4. ê²°ê³¼ ë¶„ì„
python3 scripts/analyze_performance_results.py results/performance
```

### ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ì‹œë‚˜ë¦¬ì˜¤

`configs/vllm_benchmark.yaml`ì—ì„œ ì„¤ì •:

| ì‹œë‚˜ë¦¬ì˜¤ | ì„¤ëª… | ë™ì‹œì„± | ì…ë ¥/ì¶œë ¥ í† í° |
|----------|------|--------|----------------|
| `basic_performance` | ê¸°ë³¸ ì„±ëŠ¥ ì¸¡ì • | 1 | 1024/128 |
| `concurrency_test` | ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ | 10 | 512/256 |
| `long_context` | ê¸´ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ | 2 | 4096/512 |
| `stress_test` | ê³ ë¶€í•˜ ìŠ¤íŠ¸ë ˆìŠ¤ | 20 | 2048/1024 |

### ğŸ›ï¸ í™˜ê²½ë³€ìˆ˜ ì„¤ì •

```bash
# ê¸°ë³¸ ì„¤ì •
VLLM_ENDPOINT=http://localhost:8000    # VLLM ì„œë²„ ì£¼ì†Œ
MODEL_NAME=Qwen/Qwen3-8B              # ëª¨ë¸ ì´ë¦„
SERVED_MODEL_NAME=qwen3-8b            # ì„œë¹™ ëª¨ë¸ëª…
MAX_CONCURRENCY=1                     # ìµœëŒ€ ë™ì‹œ ìš”ì²­
RANDOM_INPUT_LEN=1024                 # ì…ë ¥ í† í° ê¸¸ì´
RANDOM_OUTPUT_LEN=128                 # ì¶œë ¥ í† í° ê¸¸ì´
TZ=Asia/Seoul                         # ì‹œê°„ëŒ€ ì„¤ì •
```
### ğŸ“ˆ ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼

```
ğŸ“Š VLLM ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë¶„ì„ ê²°ê³¼
============================================================

ğŸ¯ ì‹œë‚˜ë¦¬ì˜¤: basic_performance
----------------------------------------
âœ… ì„±ê³µë¥ : 100.0% (100/100)
â±ï¸  ì´ ì†Œìš”ì‹œê°„: 45.2ì´ˆ
ğŸ”„ ìš”ì²­ ì²˜ë¦¬ëŸ‰: 2.21 req/s
ğŸ“¤ í† í° ì²˜ë¦¬ëŸ‰: 283.4 tok/s
ğŸš€ TTFT í‰ê· : 82.1ms
ğŸš€ TTFT P95: 156.3ms
âš¡ TPOT í‰ê· : 28.5ms
âš¡ TPOT P95: 45.2ms

ğŸ† ì¢…í•© ì„±ëŠ¥ ë“±ê¸‰: A
âœ¨ ëª¨ë“  ì„±ëŠ¥ ì§€í‘œê°€ ìš°ìˆ˜í•©ë‹ˆë‹¤!

```
## ğŸ”„ ë¸Œëœì¹­ & ë¦´ë¦¬ìŠ¤ íƒœê·¸

| ë¸Œëœì¹˜ | íŠ¹ì§• |
|--------|------|
| `main` | ë³´í˜¸ ë¸Œëœì¹˜Â·ìŠ¤í…Œì´ì§• í´ëŸ¬ìŠ¤í„° ìë™ ë°°í¬ |
| `release/*` | PR ë³‘í•© ì‹œ `release-{semver}` ì´ë¯¸ì§€ ë¹Œë“œÂ·GHCR í‘¸ì‹œâ†’Argo Trigger |

`docs/` ë¸Œëœì¹˜ë¥¼ ë”°ë¡œ ë‘ì–´ MkDocs ê¸°ë°˜ GitHub Pages ìš´ì˜ ê°€ëŠ¥.

## ğŸ” ì§€ì†ì  í”¼ë“œë°± ë£¨í”„

1. **ê°œë°œì**ê°€ `release-0.3.1` ì´ë¯¸ì§€ë¥¼ Push â†’ **GHCR Webhook** ë°œìƒ
2. **Argo Events Sensor**ê°€ ê°ì§€ â†’ **Argo Workflow** ì‹¤í–‰
3. **Workflow**ê°€ Deepeval(CPU) â†’ Evalchemy(GPU) ìˆœìœ¼ë¡œ ìˆ˜í–‰
4. `aggregate_metrics.py`ê°€ **ClickHouse**ì— ê²°ê³¼ ì €ì¥, **Grafana**ê°€ ìë™ ê°±ì‹ 
5. **Adaptive Card**ê°€ ìš”ì•½(ì„±ê³µ/ì‹¤íŒ¨, ì§€í‘œ ë³€í™”)ì„ **Teams ì±„ë„**ì— ì „ì†¡

## ğŸ“Š ë°ì´í„°ì…‹Â·ë²¤ì¹˜ë§ˆí¬

| ì¹´í…Œê³ ë¦¬ | ì˜ˆì‹œ | ê´€ë¦¬ ë°©ì‹ |
|----------|------|-----------|
| í‘œì¤€ ë²¤ì¹˜ë§ˆí¬ | ARC, HellaSwag, MMLU | Evalchemy Preset |
| í•œêµ­ì–´ ë²¤ì¹˜ë§ˆí¬ | Ko-MMLU, Ko-ARC | ë³„ë„ bucket `ko-benchmark` |
| ë¦¬ê·¸ë ˆì…˜ ì„¸íŠ¸ | ì„œë¹„ìŠ¤ ì¿¼ë¦¬ ìŠ¤ëƒ…ìƒ· 1k | ì¼ 1íšŒ ìµëª…í™” & SHA-256 Dedup |

**Deduplication** ì „ëµ: SHA-1/256 Hash â†’ Exact Match ì œê±° â†’ Near-Dup (LSH + Levenshtein < 0.2) í•„í„°ë¡œ DeepevalÂ·Evalchemy ì–‘ì¸¡ ë°ì´í„°ì…‹ ì¤‘ë³µ ì œê±°.

## ğŸ¯ ì„±ê³µ ì§€í‘œ

| í•­ëª© | ëª©í‘œê°’ | ì¸¡ì • ë°©ë²• |
|------|--------|-----------|
| ë¦´ë¦¬ìŠ¤â€‘toâ€‘ë¦¬í¬íŠ¸ ì§€ì—° | â‰¤ 2h | íŒŒì´í”„ë¼ì¸ ì™„ë£Œ íƒ€ì„ìŠ¤íƒ¬í”„ |
| í’ˆì§ˆ í‡´í™” ê°ì§€ìœ¨ | â‰¥ 95% | Knownâ€‘Bad ë¦¬ê·¸ë ˆì…˜ ì„¸íŠ¸ |
| íŒŒì´í”„ë¼ì¸ ì•ˆì •ì„± | ì‹¤íŒ¨ < 1%/ì›” | CronJob ì„±ê³µë¥  |

## ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ

- **ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜**: Kubernetes
- **ì›Œí¬í”Œë¡œ**: Argo Workflows, Argo Events
- **í‰ê°€ í”„ë ˆì„ì›Œí¬**: Deepeval, Evalchemy ([mlfoundations/Evalchemy](https://github.com/mlfoundations/Evalchemy))
- **ì €ì¥ì†Œ**: ClickHouse (ë©”íŠ¸ë¦­), MinIO (ë°ì´í„°ì…‹)
- **ëª¨ë‹ˆí„°ë§**: Grafana, Prometheus
- **ì•Œë¦¼**: Microsoft Teams Webhooks
- **íŒ¨í‚¤ì§•**: Helm Charts

## ğŸ“ˆ í–¥í›„ í™•ì¥ ì•„ì´ë””ì–´

| ì˜ì—­ | ì•„ì´ë””ì–´ |
|------|----------|
| **ë³´ì•ˆ** | OPA Gatekeeperë¡œ ServiceAccount ì œì•½ |
| **ë¹„ìš©** | Spot-node taint + Argo node-selector |
| **ë°ì´í„°** | ì¤‘ë³µ í•´ì‹œë¥¼ Milvusë¡œ ì´ë™í•´ ë¹ ë¥¸ ì¡°íšŒ |

## ğŸ” ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

- **ServiceAccount** ìµœì†Œ RBAC ê¶Œí•œ
- **Secrets** External Secret Operator ì—°ë™
- ëª¨ë“  **RUN_ID** ë³„ JSONL ë¡œê·¸ S3 â‰¥ 90ì¼ ë³´ì¡´

## ğŸ“š ë¬¸ì„œ

- [ì•„í‚¤í…ì²˜ ë¬¸ì„œ](docs/architecture.md)
- [ë²¤ì¹˜ë§ˆí¬ ì¶”ê°€ ê°€ì´ë“œ](docs/how-to-add-benchmark.md)
- [ê¸°ì—¬ ê°€ì´ë“œ](docs/CONTRIBUTING.md)

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ“ ì—°ë½ì²˜

- **ì œí’ˆ ì˜¤ë„ˆ**: [Product Owner Email]
- **ML Ops**: [MLOps Team Email]  
- **í”Œë«í¼ Ops**: [Platform Team Email]

---

> ğŸš€ **VLLM ëª¨ë¸ì˜ í’ˆì§ˆì„ ì§€ì†ì ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  ê°œì„ í•˜ì„¸ìš”!**