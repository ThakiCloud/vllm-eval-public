#!/bin/bash
set -e

echo "ğŸš€ macOS OrbStack VLLM ë¡œì»¬ í‰ê°€ í†µí•© ì‹¤í–‰"
echo "============================================="

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export OUTPUT_DIR="./test_results"
export RUN_ID="local_eval_$(date +%Y%m%d_%H%M%S)"

# ìƒ‰ìƒ ì½”ë“œ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# í•¨ìˆ˜ ì •ì˜
print_step() {
    echo -e "${BLUE}ğŸ“‹ $1${NC}"
}

print_success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}âš ï¸ $1${NC}"
}

print_error() {
    echo -e "${RED}âŒ $1${NC}"
}

# 1. í™˜ê²½ í™•ì¸
print_step "1. í™˜ê²½ í™•ì¸"

# Python ê°€ìƒí™˜ê²½ í™•ì¸
if [[ "$VIRTUAL_ENV" == "" ]]; then
    print_warning "ê°€ìƒí™˜ê²½ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ í™œì„±í™”í•©ë‹ˆë‹¤."
    source venv/bin/activate
fi

# í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸
print_step "2. í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸"
if ! python -c "import deepeval" 2>/dev/null; then
    print_warning "deepevalì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜ ì¤‘..."
    pip install "deepeval[all]"
fi

if ! python -c "import requests" 2>/dev/null; then
    print_warning "requestsê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜ ì¤‘..."
    pip install requests
fi

print_success "í•„ìˆ˜ íŒ¨í‚¤ì§€ í™•ì¸ ì™„ë£Œ"

# 3. ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
print_step "3. ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±"
mkdir -p $OUTPUT_DIR
print_success "ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±: $OUTPUT_DIR"

# 4. VLLM ì„œë²„ ìƒíƒœ í™•ì¸
print_step "4. VLLM ì„œë²„ ìƒíƒœ í™•ì¸"

VLLM_ENDPOINTS=("http://localhost:8000" "http://localhost:1234" "http://localhost:7860")
VLLM_FOUND=false
VLLM_ENDPOINT=""

for endpoint in "${VLLM_ENDPOINTS[@]}"; do
    if curl -s -f "$endpoint/health" > /dev/null 2>&1 || curl -s -f "$endpoint/v1/models" > /dev/null 2>&1; then
        VLLM_FOUND=true
        VLLM_ENDPOINT="$endpoint"
        break
    fi
done

if [ "$VLLM_FOUND" = true ]; then
    print_success "VLLM ì„œë²„ ë°œê²¬: $VLLM_ENDPOINT"
    export VLLM_MODEL_ENDPOINT="$VLLM_ENDPOINT/v1"
    
    # 5. ì‹¤ì œ VLLM ì„œë²„ í…ŒìŠ¤íŠ¸
    print_step "5. ì‹¤ì œ VLLM ì„œë²„ë¡œ í‰ê°€ ì‹¤í–‰"
    python scripts/run_vllm_deepeval_test.py
    
else
    print_warning "VLLM ì„œë²„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Mock í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."
    
    # 5. Mock í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print_step "5. Mock ëª¨ë¸ë¡œ í‰ê°€ ì‹¤í–‰"
    python scripts/run_simple_deepeval_test.py
fi

# 6. ê²°ê³¼ ìš”ì•½
print_step "6. í‰ê°€ ê²°ê³¼ ìš”ì•½"

echo ""
echo "ğŸ“Š í‰ê°€ ì™„ë£Œ!"
echo "============"
echo "ì‹¤í–‰ ID: $RUN_ID"
echo "ê²°ê³¼ ë””ë ‰í† ë¦¬: $OUTPUT_DIR"
echo ""

# ìƒì„±ëœ ê²°ê³¼ íŒŒì¼ ë‚˜ì—´
if [ -d "$OUTPUT_DIR" ]; then
    echo "ğŸ“ ìƒì„±ëœ ê²°ê³¼ íŒŒì¼:"
    for file in "$OUTPUT_DIR"/*.json; do
        if [ -f "$file" ]; then
            echo "  - $(basename "$file")"
        fi
    done
    echo ""
fi

# 7. ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
print_step "7. ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°"

# ê°€ì¥ ìµœê·¼ ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
LATEST_RESULT=$(ls -t "$OUTPUT_DIR"/*.json 2>/dev/null | head -1)

if [ -n "$LATEST_RESULT" ]; then
    echo "ìµœì‹  ê²°ê³¼ íŒŒì¼: $(basename "$LATEST_RESULT")"
    echo ""
    
    # ìš”ì•½ ì •ë³´ ì¶œë ¥
    if command -v jq >/dev/null 2>&1; then
        echo "ğŸ“ˆ ìš”ì•½ ì •ë³´:"
        jq -r '
            if .summary then
                "  ëª¨ë¸: " + .summary.model_name +
                "\n  ì´ í…ŒìŠ¤íŠ¸: " + (.summary.total_tests | tostring) +
                (if .summary.average_score then "\n  í‰ê·  ì ìˆ˜: " + (.summary.average_score | tostring) else "" end) +
                (if .summary.status then "\n  ìƒíƒœ: " + .summary.status else "" end)
            else
                "  ìš”ì•½ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            end
        ' "$LATEST_RESULT"
    else
        echo "jqê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ìš”ì•½ ì •ë³´ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        echo "ê²°ê³¼ íŒŒì¼ì„ ì§ì ‘ í™•ì¸í•´ì£¼ì„¸ìš”: $LATEST_RESULT"
    fi
else
    print_warning "ìƒì„±ëœ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
fi

echo ""
print_success "ë¡œì»¬ VLLM í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"

# 8. ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
print_step "8. ë‹¤ìŒ ë‹¨ê³„"
echo "ê²°ê³¼ë¥¼ í™•ì¸í•˜ë ¤ë©´:"
echo "  1. JSON íŒŒì¼ ì§ì ‘ ë³´ê¸°: cat $OUTPUT_DIR/*.json"
echo "  2. ë¸Œë¼ìš°ì €ì—ì„œ ë³´ê¸°: open $OUTPUT_DIR"
if [ "$VLLM_FOUND" = false ]; then
    echo ""
    echo "ì‹¤ì œ VLLM ì„œë²„ë¡œ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´:"
    echo "  1. VLLM ì„œë²„ ì‹œì‘:"
    echo "     docker run -d --name vllm-server --gpus all -p 8000:8000 \\"
    echo "       vllm/vllm-openai:latest --model Qwen/Qwen2-7B-Instruct \\"
    echo "       --served-model-name qwen3-8b"
    echo "  2. ì´ ìŠ¤í¬ë¦½íŠ¸ ë‹¤ì‹œ ì‹¤í–‰: ./scripts/run_complete_local_evaluation.sh"
fi
echo "" 