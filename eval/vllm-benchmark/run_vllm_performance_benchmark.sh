#!/bin/bash
set -euo pipefail

# μ„±λ¥ λ²¤μΉλ§ν¬ μ‹¤ν–‰ μ¤ν¬λ¦½νΈ
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
CONFIG_FILE="${PROJECT_ROOT}/configs/vllm_benchmark.json"

# κΈ°λ³Έ μ„¤μ •
VLLM_ENDPOINT="${VLLM_ENDPOINT:-http://localhost:8000}"
RESULTS_DIR="${PROJECT_ROOT}/results/performance"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")

echo "π€ VLLM μ„±λ¥ λ²¤μΉλ§ν¬ μ‹μ‘"
echo "π“΅ μ—”λ“ν¬μΈνΈ: $VLLM_ENDPOINT"
echo "π“ κ²°κ³Ό λ””λ ‰ν† λ¦¬: $RESULTS_DIR"

# κ²°κ³Ό λ””λ ‰ν† λ¦¬ μƒμ„±
mkdir -p "$RESULTS_DIR"

# yq μ„¤μΉ ν™•μΈ
if ! command -v yq &> /dev/null; then
    echo "β 'yq'κ°€ ν•„μ”ν•©λ‹λ‹¤. μ„¤μΉ: brew install yq"
    exit 1
fi

# μ‹λ‚λ¦¬μ¤ κ°μ ν™•μΈ
scenario_count=$(yq e '.vllm_benchmark.scenarios | length' "$CONFIG_FILE")
echo "π“ μ΄ ${scenario_count}κ° μ‹λ‚λ¦¬μ¤ μ‹¤ν–‰ μμ •"

# κ° μ‹λ‚λ¦¬μ¤ μ‹¤ν–‰
for i in $(seq 0 $((scenario_count - 1))); do
    # μ‹λ‚λ¦¬μ¤ μ •λ³΄ μ¶”μ¶
    name=$(yq e ".vllm_benchmark.scenarios[$i].name" "$CONFIG_FILE")
    description=$(yq e ".vllm_benchmark.scenarios[$i].description" "$CONFIG_FILE")
    model=$(yq e ".vllm_benchmark.scenarios[$i].model" "$CONFIG_FILE")
    served_model_name=$(yq e ".vllm_benchmark.scenarios[$i].served_model_name" "$CONFIG_FILE")
    max_concurrency=$(yq e ".vllm_benchmark.scenarios[$i].max_concurrency" "$CONFIG_FILE")
    random_input_len=$(yq e ".vllm_benchmark.scenarios[$i].random_input_len" "$CONFIG_FILE")
    random_output_len=$(yq e ".vllm_benchmark.scenarios[$i].random_output_len" "$CONFIG_FILE")
    num_prompts=$(yq e ".vllm_benchmark.scenarios[$i].num_prompts" "$CONFIG_FILE")
    
    echo ""
    echo "β–¶ [$((i+1))/$scenario_count] μ‹λ‚λ¦¬μ¤: $name"
    echo "  π“ μ„¤λ…: $description"
    echo "  π― λ¨λΈ: $model"
    echo "  π”€ λ™μ‹μ„±: $max_concurrency"
    echo "  π“¥ μ…λ ¥: ${random_input_len} ν† ν°"
    echo "  π“¤ μ¶λ ¥: ${random_output_len} ν† ν°"
    echo "  π“ ν”„λ΅¬ν”„νΈ: $num_prompts κ°"
    
    # μ‹λ‚λ¦¬μ¤λ³„ κ²°κ³Ό λ””λ ‰ν† λ¦¬
    scenario_dir="${RESULTS_DIR}/${name}_${TIMESTAMP}"
    mkdir -p "$scenario_dir"
    
    # Dockerλ΅ λ²¤μΉλ§ν¬ μ‹¤ν–‰
    docker run --rm \
        -v "$scenario_dir:/results" \
        -e VLLM_ENDPOINT="$VLLM_ENDPOINT" \
        -e MODEL_NAME="$model" \
        -e SERVED_MODEL_NAME="$served_model_name" \
        -e MAX_CONCURRENCY="$max_concurrency" \
        -e RANDOM_INPUT_LEN="$random_input_len" \
        -e RANDOM_OUTPUT_LEN="$random_output_len" \
        -e NUM_PROMPTS="$num_prompts" \
        -e TZ=Asia/Seoul \
        vllm-benchmark:latest
    
    echo "  β… μ‹λ‚λ¦¬μ¤ '$name' μ™„λ£"
done

echo ""
echo "π‰ λ¨λ“  μ„±λ¥ λ²¤μΉλ§ν¬ μ™„λ£!"
echo "π“ κ²°κ³Ό μ„μΉ: $RESULTS_DIR"
echo "π“ κ²°κ³Ό λ¶„μ„μ„ μ„ν•΄ λ‹¤μ λ…λ Ήμ–΄ μ‹¤ν–‰:"
echo "   python3 scripts/analyze_performance_results.py $RESULTS_DIR" 