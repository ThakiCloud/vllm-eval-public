[tool:pytest]
# Pytest configuration for Deepeval tests

# Test discovery
testpaths = eval/deepeval_tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Output options
addopts = 
    -v
    --tb=short
    --strict-markers
    --strict-config
    --json-report
    --json-report-file=/results/deepeval_results.json
    --html=/results/deepeval_report.html
    --self-contained-html
    --cov=eval
    --cov-report=html:/results/coverage_html
    --cov-report=xml:/results/coverage.xml
    --cov-report=term-missing
    --cov-fail-under=80

# Markers
markers =
    rag: RAG evaluation tests
    hallucination: Hallucination detection tests
    context: Context relevance tests
    faithfulness: Faithfulness evaluation tests
    slow: Slow running tests
    integration: Integration tests
    unit: Unit tests

# Logging
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Warnings
filterwarnings =
    ignore::UserWarning
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning

# Timeout
timeout = 300
timeout_method = thread

# Parallel execution
workers = auto
dist = worksteal 